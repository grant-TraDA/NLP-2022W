{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MondayPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MondayPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\MondayPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MondayPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")  # Punkt Sentence Tokenizer\n",
    "nltk.download(\"averaged_perceptron_tagger\")  # Part of Speech Tagger\n",
    "nltk.download(\"wordnet\")  # a lexical database of English; useful for synonyms, hyponyms, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"weren't\",\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'some',\n",
       " 'over',\n",
       " 'wouldn',\n",
       " 'themselves',\n",
       " 'during',\n",
       " 'was',\n",
       " 'hasn']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "random.sample(stopwords.words('english'), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_dataset_train = pd.read_csv('../data/LIAR-PLUS/train2.tsv', sep='\\t', header = None)\n",
    "liar_dataset_test = pd.read_csv('../data/LIAR-PLUS/test2.tsv', sep='\\t', header = None)\n",
    "liar_dataset_valid = pd.read_csv('../data/LIAR-PLUS/val2.tsv', sep='\\t', header = None)\n",
    "liar_dataset = pd.concat([liar_dataset_train, liar_dataset_test, liar_dataset_valid], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_dataset = liar_dataset.iloc[:, [2, 3, 15]]\n",
    "liar_dataset = liar_dataset.rename(columns = {2: 'label', 3: 'statements', 15: 'justification'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_dataset.dropna(inplace=True)\n",
    "liar_dataset.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statements</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>That's a premise that he fails to back up. Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>Surovell said the decline of coal \"started whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Obama said he would have voted against the ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>The release may have a point that Mikulskis co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>Crist said that the economic \"turnaround start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12687</th>\n",
       "      <td>half-true</td>\n",
       "      <td>For the first time in more than a decade, impo...</td>\n",
       "      <td>In 2009, 17 percent of the U. S. 's oil import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12688</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Says Donald Trump has bankrupted his companies...</td>\n",
       "      <td>Clinton said, Trump has \"bankrupted his compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12689</th>\n",
       "      <td>true</td>\n",
       "      <td>John McCain and George Bush have \"absolutely n...</td>\n",
       "      <td>\"I don't think that there should be a mandate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12690</th>\n",
       "      <td>false</td>\n",
       "      <td>A new poll shows 62 percent support the presid...</td>\n",
       "      <td>But the poll doesn't say that. Several days af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12691</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>No one claims the report vindicating New Jerse...</td>\n",
       "      <td>Giuliani said \"no one\" called the Mastro repor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12692 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                         statements  \\\n",
       "0            false  Says the Annies List political group supports ...   \n",
       "1        half-true  When did the decline of coal start? It started...   \n",
       "2      mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3            false  Health care reform legislation is likely to ma...   \n",
       "4        half-true  The economic turnaround started at the end of ...   \n",
       "...            ...                                                ...   \n",
       "12687    half-true  For the first time in more than a decade, impo...   \n",
       "12688  mostly-true  Says Donald Trump has bankrupted his companies...   \n",
       "12689         true  John McCain and George Bush have \"absolutely n...   \n",
       "12690        false  A new poll shows 62 percent support the presid...   \n",
       "12691  barely-true  No one claims the report vindicating New Jerse...   \n",
       "\n",
       "                                           justification  \n",
       "0      That's a premise that he fails to back up. Ann...  \n",
       "1      Surovell said the decline of coal \"started whe...  \n",
       "2      Obama said he would have voted against the ame...  \n",
       "3      The release may have a point that Mikulskis co...  \n",
       "4      Crist said that the economic \"turnaround start...  \n",
       "...                                                  ...  \n",
       "12687  In 2009, 17 percent of the U. S. 's oil import...  \n",
       "12688  Clinton said, Trump has \"bankrupted his compan...  \n",
       "12689  \"I don't think that there should be a mandate ...  \n",
       "12690  But the poll doesn't say that. Several days af...  \n",
       "12691  Giuliani said \"no one\" called the Mastro repor...  \n",
       "\n",
       "[12692 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_dataset['label'] = liar_dataset['label'].replace({\n",
    "    'false' : 0,\n",
    "    'barely-true' : 1,\n",
    "    'pants-fire' : 2,\n",
    "    'half-true' : 3,\n",
    "    'mostly-true' : 4,\n",
    "    'true' : 5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statements</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>That's a premise that he fails to back up. Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>Surovell said the decline of coal \"started whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Obama said he would have voted against the ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>The release may have a point that Mikulskis co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>Crist said that the economic \"turnaround start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12687</th>\n",
       "      <td>3</td>\n",
       "      <td>For the first time in more than a decade, impo...</td>\n",
       "      <td>In 2009, 17 percent of the U. S. 's oil import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12688</th>\n",
       "      <td>4</td>\n",
       "      <td>Says Donald Trump has bankrupted his companies...</td>\n",
       "      <td>Clinton said, Trump has \"bankrupted his compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12689</th>\n",
       "      <td>5</td>\n",
       "      <td>John McCain and George Bush have \"absolutely n...</td>\n",
       "      <td>\"I don't think that there should be a mandate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12690</th>\n",
       "      <td>0</td>\n",
       "      <td>A new poll shows 62 percent support the presid...</td>\n",
       "      <td>But the poll doesn't say that. Several days af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12691</th>\n",
       "      <td>1</td>\n",
       "      <td>No one claims the report vindicating New Jerse...</td>\n",
       "      <td>Giuliani said \"no one\" called the Mastro repor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12692 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                         statements  \\\n",
       "0          0  Says the Annies List political group supports ...   \n",
       "1          3  When did the decline of coal start? It started...   \n",
       "2          4  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3          0  Health care reform legislation is likely to ma...   \n",
       "4          3  The economic turnaround started at the end of ...   \n",
       "...      ...                                                ...   \n",
       "12687      3  For the first time in more than a decade, impo...   \n",
       "12688      4  Says Donald Trump has bankrupted his companies...   \n",
       "12689      5  John McCain and George Bush have \"absolutely n...   \n",
       "12690      0  A new poll shows 62 percent support the presid...   \n",
       "12691      1  No one claims the report vindicating New Jerse...   \n",
       "\n",
       "                                           justification  \n",
       "0      That's a premise that he fails to back up. Ann...  \n",
       "1      Surovell said the decline of coal \"started whe...  \n",
       "2      Obama said he would have voted against the ame...  \n",
       "3      The release may have a point that Mikulskis co...  \n",
       "4      Crist said that the economic \"turnaround start...  \n",
       "...                                                  ...  \n",
       "12687  In 2009, 17 percent of the U. S. 's oil import...  \n",
       "12688  Clinton said, Trump has \"bankrupted his compan...  \n",
       "12689  \"I don't think that there should be a mandate ...  \n",
       "12690  But the poll doesn't say that. Several days af...  \n",
       "12691  Giuliani said \"no one\" called the Mastro repor...  \n",
       "\n",
       "[12692 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = liar_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statements</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>That's a premise that he fails to back up. Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>Surovell said the decline of coal \"started whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>Obama said he would have voted against the ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>The release may have a point that Mikulskis co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>Crist said that the economic \"turnaround start...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                         statements  \\\n",
       "0      0  Says the Annies List political group supports ...   \n",
       "1      3  When did the decline of coal start? It started...   \n",
       "2      4  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3      0  Health care reform legislation is likely to ma...   \n",
       "4      3  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                       justification  \n",
       "0  That's a premise that he fails to back up. Ann...  \n",
       "1  Surovell said the decline of coal \"started whe...  \n",
       "2  Obama said he would have voted against the ame...  \n",
       "3  The release may have a point that Mikulskis co...  \n",
       "4  Crist said that the economic \"turnaround start...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.fillna(\"null data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_stopwords = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if if_stopwords:\n",
    "    train_dataset[\"statements\"] = train_dataset[\"statements\"].str.lower().str.replace(\"’\", \"'\")\n",
    "    train_dataset[\"statements\"] = train_dataset[\"statements\"].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "    train_dataset[\"justification\"] = train_dataset[\"justification\"].str.lower().str.replace(\"’\", \"'\")\n",
    "    train_dataset[\"justification\"] = train_dataset[\"justification\"].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statements</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>says annies list political group supports thir...</td>\n",
       "      <td>that's premise fails back up. annie's list mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>decline coal start? started natural gas took s...</td>\n",
       "      <td>surovell said decline coal \"started natural ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>hillary clinton agrees john mccain \"by voting ...</td>\n",
       "      <td>obama said would voted amendment present. thou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>health care reform legislation likely mandate ...</td>\n",
       "      <td>release may point mikulskis comment could open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>economic turnaround started end term.</td>\n",
       "      <td>crist said economic \"turnaround started end te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                         statements  \\\n",
       "0      0  says annies list political group supports thir...   \n",
       "1      3  decline coal start? started natural gas took s...   \n",
       "2      4  hillary clinton agrees john mccain \"by voting ...   \n",
       "3      0  health care reform legislation likely mandate ...   \n",
       "4      3              economic turnaround started end term.   \n",
       "\n",
       "                                       justification  \n",
       "0  that's premise fails back up. annie's list mak...  \n",
       "1  surovell said decline coal \"started natural ga...  \n",
       "2  obama said would voted amendment present. thou...  \n",
       "3  release may point mikulskis comment could open...  \n",
       "4  crist said economic \"turnaround started end te...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_text_fn = {\n",
    "    \"no_punctuation\": lambda txt: re.sub(r'[^\\w\\s]','', txt),\n",
    "    \"no_special_symbols\": lambda txt: re.sub('[$,#,&]', '', txt),\n",
    "    \"no_digits\": lambda txt: re.sub('\\d*', '', txt),\n",
    "    \"no_www\": lambda txt: re.sub('w{3}', '', txt),\n",
    "    \"no_urls\": lambda txt: re.sub('http\\S+', '', txt),\n",
    "    \"no_spaces\": lambda txt: re.sub('\\s+', ' ', txt),\n",
    "    \"no_single_chars\": lambda txt: re.sub(r'\\s+[a-zA-Z]\\s+', '', txt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, pipeline = preprocessing_text_fn):\n",
    "    text = str(text)\n",
    "    for fn in pipeline.keys():\n",
    "        text = pipeline[fn](text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['then',\n",
       " 'her',\n",
       " 'needn',\n",
       " 'because',\n",
       " 'themselves',\n",
       " 'from',\n",
       " 'after',\n",
       " 'are',\n",
       " 'is',\n",
       " 'do',\n",
       " \"needn't\",\n",
       " 'who',\n",
       " 'that',\n",
       " 'not',\n",
       " \"isn't\",\n",
       " \"should've\",\n",
       " 'did',\n",
       " 'some',\n",
       " 'those',\n",
       " 'these']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOP_WORDS = [preprocessing_text_fn[\"no_punctuation\"](word) for word in stop_words]\n",
    "random.sample(stop_words, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_without_stopwords(text, stop_words=STOP_WORDS):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sequence = [word for word in word_tokens if not word.lower() in stop_words]\n",
    "    return filtered_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statements</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>says annies list political group supports thir...</td>\n",
       "      <td>thats premise fails back up annies list makes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>decline coal start started natural gas took st...</td>\n",
       "      <td>surovell said decline coal started natural gas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>hillary clinton agrees john mccain by voting g...</td>\n",
       "      <td>obama said would voted amendment present thoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>health care reform legislation likely mandate ...</td>\n",
       "      <td>release may point mikulskis comment could open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>economic turnaround started end term</td>\n",
       "      <td>crist said economic turnaround started end ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>chicago bears starting quarterbacks last years...</td>\n",
       "      <td>vos specifically used word fired means faculty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>jim dunnam lived district represents years now</td>\n",
       "      <td>determining would take significant detective w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>im person stage worked actively last year pass...</td>\n",
       "      <td>however bill another one sponsored majority le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>however took million oregon lottery funds port...</td>\n",
       "      <td>johnson correct many factors played role lotte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>says gop primary opponents glenn grothman joe ...</td>\n",
       "      <td>considering million figure covers years reason...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                         statements  \\\n",
       "0      0  says annies list political group supports thir...   \n",
       "1      3  decline coal start started natural gas took st...   \n",
       "2      4  hillary clinton agrees john mccain by voting g...   \n",
       "3      0  health care reform legislation likely mandate ...   \n",
       "4      3               economic turnaround started end term   \n",
       "5      5  chicago bears starting quarterbacks last years...   \n",
       "6      1     jim dunnam lived district represents years now   \n",
       "7      3  im person stage worked actively last year pass...   \n",
       "8      3  however took million oregon lottery funds port...   \n",
       "9      4  says gop primary opponents glenn grothman joe ...   \n",
       "\n",
       "                                       justification  \n",
       "0  thats premise fails back up annies list makes ...  \n",
       "1  surovell said decline coal started natural gas...  \n",
       "2  obama said would voted amendment present thoug...  \n",
       "3  release may point mikulskis comment could open...  \n",
       "4  crist said economic turnaround started end ter...  \n",
       "5  vos specifically used word fired means faculty...  \n",
       "6  determining would take significant detective w...  \n",
       "7  however bill another one sponsored majority le...  \n",
       "8  johnson correct many factors played role lotte...  \n",
       "9  considering million figure covers years reason...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"statements\"] = train_dataset[\"statements\"].apply(preprocess_text)\n",
    "train_dataset[\"justification\"] = train_dataset[\"justification\"].apply(preprocess_text)\n",
    "train_dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_lemmatize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MondayPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\MondayPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "if if_lemmatize:\n",
    "    \n",
    "    import nltk\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    train_dataset[\"statements\"] = train_dataset[\"statements\"].str.lower().str.replace(\"’\", \"'\")\n",
    "    train_dataset[\"statements\"] = train_dataset[\"statements\"].apply(lambda x: ' '.join([wnl.lemmatize(word) for word in word_tokenize(x)]))\n",
    "    train_dataset[\"justification\"] = train_dataset[\"justification\"].str.lower().str.replace(\"’\", \"'\")\n",
    "    train_dataset[\"justification\"] = train_dataset[\"justification\"].apply(lambda x: ' '.join([wnl.lemmatize(word) for word in word_tokenize(x)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SJ = False\n",
    "\n",
    "if SJ:\n",
    "    train_text = (train_dataset['justification'] + \" \" + train_dataset['statements']).values\n",
    "else:\n",
    "    train_text = train_dataset['justification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "train_labels = to_categorical(train_labels, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit length of each article\n",
    "max_length = 3300\n",
    "lengths = np.array([len(x) for x in train_text])\n",
    "train_text = train_text[lengths < max_length]\n",
    "train_labels = train_labels[lengths < max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3227"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check actual max length of an article\n",
    "article_length = max(np.array([len(x) for x in train_text]))\n",
    "article_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2vec model with vector size = 100\n",
    "vec_size = 100\n",
    "\n",
    "# workers - number of CPU threads\n",
    "word_model = gensim.models.Word2Vec(train_text, vector_size = vec_size, window = 5, workers = 12)\n",
    "word_model.train(train_text, epochs = 10, total_examples = len(train_text))\n",
    "wv = word_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "vocabulary_size = len(tokenizer.word_index) + 1\n",
    "encoded_articles = tokenizer.texts_to_sequences(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_articles = pad_sequences(encoded_articles, maxlen = article_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12683, 3227)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = np.zeros(shape=(vocabulary_size, vec_size))\n",
    "for w, i in tokenizer.word_index.items():\n",
    "    ind = wv.has_index_for(w)\n",
    "    if ind:\n",
    "        emb_matrix[i] = wv.get_vector(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(padded_articles, train_labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import Constant\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, LSTM\n",
    "from keras.layers import ReLU\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(input_dim = vocabulary_size, \n",
    "                    output_dim = vec_size,\n",
    "                    input_length = article_length,\n",
    "                    embeddings_initializer = Constant(emb_matrix))\n",
    "         )\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 3227, 100)         2552300   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 3227, 32)          17024     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 103264)            0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                6608960   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,179,426\n",
      "Trainable params: 9,179,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def keras_f1_score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(),loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "149/149 [==============================] - 17s 106ms/step - loss: 0.4970 - accuracy: 0.1884 - val_loss: 0.4462 - val_accuracy: 0.1980\n",
      "Epoch 2/10\n",
      "149/149 [==============================] - 16s 106ms/step - loss: 0.4564 - accuracy: 0.2148 - val_loss: 0.4469 - val_accuracy: 0.2053\n",
      "Epoch 3/10\n",
      "149/149 [==============================] - 16s 105ms/step - loss: 0.4169 - accuracy: 0.3445 - val_loss: 0.4741 - val_accuracy: 0.1933\n",
      "Epoch 4/10\n",
      "149/149 [==============================] - 16s 104ms/step - loss: 0.3357 - accuracy: 0.5146 - val_loss: 0.5304 - val_accuracy: 0.1908\n",
      "Epoch 5/10\n",
      "149/149 [==============================] - 16s 105ms/step - loss: 0.2484 - accuracy: 0.6824 - val_loss: 0.6866 - val_accuracy: 0.1785\n",
      "Epoch 6/10\n",
      "149/149 [==============================] - 16s 106ms/step - loss: 0.1777 - accuracy: 0.7944 - val_loss: 0.8387 - val_accuracy: 0.1757\n",
      "Epoch 7/10\n",
      "149/149 [==============================] - 15s 104ms/step - loss: 0.1195 - accuracy: 0.8720 - val_loss: 1.0519 - val_accuracy: 0.1886\n",
      "Epoch 8/10\n",
      "149/149 [==============================] - 16s 108ms/step - loss: 0.0825 - accuracy: 0.9184 - val_loss: 1.2420 - val_accuracy: 0.1757\n",
      "Epoch 9/10\n",
      "149/149 [==============================] - 16s 106ms/step - loss: 0.0572 - accuracy: 0.9478 - val_loss: 1.4804 - val_accuracy: 0.1760\n",
      "Epoch 10/10\n",
      "149/149 [==============================] - 16s 110ms/step - loss: 0.0447 - accuracy: 0.9635 - val_loss: 1.6495 - val_accuracy: 0.1829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b85ae7c908>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298/298 [==============================] - 10s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "train_pred = np.argmax(model.predict(x_train), axis=1)\n",
    "train_truth = np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9834945332211943"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy_score(train_truth, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833783735277551"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 score\n",
    "balanced_accuracy_score(train_pred, train_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 3s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "test_truth = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18290760012614318"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy_score(test_pred, test_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17367251099982592"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanced accuracy\n",
    "balanced_accuracy_score(test_truth, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
